{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyNBS import data_import_tools as dit\n",
    "from pyNBS import network_propagation as prop\n",
    "from pyNBS import pyNBS_core as core\n",
    "from pyNBS import pyNBS_single\n",
    "from pyNBS import consensus_clustering as cc\n",
    "from pyNBS import pyNBS_plotting as plot\n",
    "\n",
    "import os\n",
    "import time\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "First, we must load the somatic mutation and network data for running pyNBS along with any additional parameters we would like to change in the algorithm performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load binary somatic mutation data\n",
    "The binary somatic mutation data file can be represented in two file formats:  \n",
    "The default format for the binary somatic mutation data file is the ```list``` format. This file format is a 2-column csv or tsv list where the 1st column is a sample/patient and the 2nd column is a gene mutated in the sample/patient. There are no headers in this file format. Loading data with the list format is typically faster than loading data from the matrix format.The following text is the list representation of the matrix above.\n",
    "```\n",
    "TCGA-04-1638\tA2M\n",
    "TCGA-23-1029\tA1CF\n",
    "TCGA-23-2647\tA2BP1\n",
    "TCGA-24-1847\tA2M\n",
    "TCGA-42-2589\tA1CF\n",
    "```\n",
    "\n",
    "The ```matrix``` binary somatic mutation data format is the format that data for this example is currently represented. This file format is a binary csv or tsv matrix with rows represent samples/patients and columns represent genes.  The following table is a small excerpt of a matrix somatic mutation data file:  \n",
    "\n",
    "||A1CF|A2BP1|A2M|\n",
    "|-|-|-|-|\n",
    "|TCGA-04-1638|0|0|1|\n",
    "|TCGA-23-1029|1|0|0|\n",
    "|TCGA-23-2647|0|1|0|\n",
    "|TCGA-24-1847|0|0|1|\n",
    "|TCGA-42-2589|1|0|0|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The only required file here is the file path to the somatic mutation data\n",
    "# However, in this example, the data is not formatted in the default 2-column tab-separated list, so we set the\n",
    "# file loading parameters explicitly below\n",
    "\n",
    "sm_data_filepath = './Example_Notebook_Data/Mutation_Files/OV_sm_mat_Hofree.csv'\n",
    "sm_mat = dit.load_binary_mutation_data(sm_data_filepath, filetype='matrix', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load molecular network\n",
    "The network file is a 2-column text file representing an unweighted network. Each row represents a single edge in the molecular network.    \n",
    "  \n",
    "Notes about the network file:  \n",
    " - The default column delimiter is a tab character '\\t' but a different delimiter can be defined by the user here or in the parameter file with the \"net_filedelim\" parameter.\n",
    " - The network must not contain duplicate edges (e.g. TP53\\tMDM2 is equivalent to MDM2\\tTP53)\n",
    " - The network must not contain self-edges (e.g. TP53\\tTP53)\n",
    " - Only the first two columns of a network file are read as edges for the network, all other columns will be ignored.\n",
    " - The load_network function also includes options to read in edge- or label-shuffled versions of the network, but by default, these options are turned off.\n",
    " \n",
    "An excerpt of the first five rows of the PID network file is given below:  \n",
    "```\n",
    "A1BG\tA2M\n",
    "A1BG\tAKT1\n",
    "A1BG\tGRB2\n",
    "A1BG\tPIK3CA\n",
    "A1BG\tPIK3R1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network File Loaded: ./Example_Notebook_Data/Network_Files/HM90.sif\n"
     ]
    }
   ],
   "source": [
    "# The only required parameter for this function is the network file path\n",
    "\n",
    "network_filepath = './Example_Notebook_Data/Network_Files/HM90.sif'\n",
    "network = dit.load_network_file(network_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting result output options\n",
    "The following code is completely optional for the user. Allows users to pre-define a directory to save intermediate and final results to and establishes a file name prefix for those files in the output directory folder. Also creates the output directory if it does not already exist. The result of this cell will be a dictionary that can be passed optionally to functions to save results.\n",
    "\n",
    "**Note:** The key assumption here is that if the user passes **save_args to the function that contains a valid file path to a directory in ```outdir```, the result of that particular call of the function will be saved to the given ```outdir```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional: Setting the output directory for files to be saved in\n",
    "outdir = './Results/Hofree_OV/'\n",
    "\n",
    "# Optional: Creating above output directory if it doesn't already exist\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "# Optional: Setting a filename prefix for all files saved to outdir\n",
    "job_name = 'HofreeOV'\n",
    "\n",
    "# Constructs dictionary to be passed as \"save_args\" to functions if output to be saved\n",
    "save_args = {'outdir': outdir, 'job_name': job_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Construct regularization graph for use in network-regularized NMF\n",
    "In this step, we will construct the graph used in the network-regularized non-negative matrix factorization (netNMF) step of pyNBS. This network is a K-nearest neighbor (KNN) network constructed from the network influence matrix (Vandin et al 2011*) of the molecular network being used to stratify tumor samples. The graph laplacian of this KNN network (knnGlap) is used as the regularizer in the following netNMF steps. This step uses the `network_inf_KNN_glap()` function in the pyNBS_core module. The function constructs the knnGlap with the following steps:  \n",
    "  \n",
    "__Steps to construct knnGlap:__\n",
    "1. Construct the network influence matrix as described by Vandin et al 2011*\n",
    "> i. Construct laplacian matrix of the molecular network.  \n",
    "> ii. Adjust diagonal of the laplacian matrix by small gamma factor (default 0.01)  \n",
    "> iii. Calculate the inverse of the diagonal-adjusted graph laplacian from (ii) to get the network influence matrix <br> Note: _This method is significantly faster and gives similar results as the original method used previously in Hofree's NBS v0.2.0, which calculated the pseudoinverse of each network component._\n",
    "2. Construct KNN graph by conneting each node to its k nearest neighbors by influence score (default k is 11)\n",
    "3. Calculate graph laplacian of this new KNN graph and return it as knnGlap\n",
    "\n",
    "---\n",
    "* Fabio Vandin, Eli Upfal, and Benjamin J. Raphael. Journal of Computational Biology. March 2011, 18(3): 507-522. https://doi.org/10.1089/cmb.2010.0265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph influence matrix calculated: 30.9956521988 seconds\n",
      "Graph laplacian of KNN network from influence matrix calculated: 46.2399120331 seconds\n"
     ]
    }
   ],
   "source": [
    "# Constructing knnGlap\n",
    "knnGlap = core.network_inf_KNN_glap(network)\n",
    "\n",
    "##########################################################################################################\n",
    "# The resulting matrix can be very large, so we choose not to save the intermediate result here\n",
    "# To run this function and save the KNN graph laplaican to the output directory 'outdir' given above:\n",
    "# Uncomment and run the following line instead:\n",
    "# knnGlap = core.network_inf_KNN_glap(network, **save_args)\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct network propagation kernel matrix\n",
    "Due to the multiple subsampling and propagation steps used in pyNBS, we have found that the algorithm can be significantly sped up for large numbers of subsampling and propagation iterations if a network propagation kernel can be pre-computed. Here we compute this propagation kernel by propagating the all genes in the molecular network independently of one another. The propagation profile of each tumor is then simply the row sums of all genes marked as mutated in each tumor, rather than having to perform the full network propagation step again after each subsampling of the data. Re-propagating at each subsampling step can be time consuming due to the matrix inversion calculation required by our implementation of the network propagation algorithm, which is based on the closed form of the random walk model over networks presented by the HotNet2 paper (Leiserson et al 2015*). This step uses the `network_propagation()` function in the network_propagation module of pyNBS.<br>\n",
    "\n",
    "The general formulation of the closed form random-walk propagation for a given network: <br>\n",
    "$$F_t = (1-\\alpha)*F_0*(I-\\alpha*A)^{-1}$$<br>\n",
    "$F_0$ here is typically the binary mutation matrix, but for the kernel, it is the same as the identity matrix. A is the normalized adjcency matrix of the molecular network. The normalized adjacency matrix is calculated as $A*D^{-1}$ where D is the row/column-matched diagonalized node degree of the molecular network. $\\alpha$ is the network propagation constant, a default value of 0.7 is used here (same as by Hofree), but results may vary if $\\alpha$ is changed. Analysis by Hofree et al suggest that setting $\\alpha$ between 0.5-0.8 gives relatively stable results.\n",
    "  \n",
    "Additional notes about how we perform random-walk based network propagation:  \n",
    " - We first separate the molecular network into each connected component and then perform network propagation for each connected component and concatenate the resulting kernel matrices along the diagonal for each subgraph.\n",
    " - Our default normalized adjacency matrix is not symmetric, but an option is available to calculate a symmetric degree-normalized adjacency matrix defined as $D^{-0.5} * A * D^{-0.5}$.  \n",
    " \n",
    "---\n",
    "* Leiserson MDM, Vandin F, Wu H-T, et al. Pan-Cancer Network Analysis Identifies Combinations of Rare Somatic Mutations across Pathways and Protein Complexes. Nature genetics. 2015;47(2):106-114. doi:10.1038/ng.3168."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network propagation coefficient\n",
    "The current network propagation coefficient ($\\alpha$) is currently set to 0.7 and must range between 0 and 1. This parameter can be tuned and changing it may have a result on the final propagation results. Previous results from Hofree et al 2013 suggest that values between 0.5 and 0.8 produce relatively robust results, but we suspect that the optimal value may be dependent on certain network properties such as edge density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set or change network propagation coefficient if desired\n",
    "alpha = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct identity matrix of network\n",
    "network_nodes = network.nodes()\n",
    "network_I = pd.DataFrame(np.identity(len(network_nodes)), index=network_nodes, columns=network_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing network propagation with alpha: 0.7\n",
      "Network Propagation Complete: 131.982158899 seconds\n"
     ]
    }
   ],
   "source": [
    "# Construct network propagation kernel\n",
    "kernel = prop.network_propagation(network, network_I, alpha=alpha)\n",
    "\n",
    "##########################################################################################################\n",
    "# The resulting matrix can be very large, so we choose not to save the intermediate result here\n",
    "# To run this function and save the propagation kernel to the output directory 'outdir' given above,\n",
    "# Uncomment and run the following two lines instead of the above line:\n",
    "# save_args['iteration_label']='kernel'\n",
    "# kernel = prop.network_propagation(network, network_I, alpha=alpha, **save_args)\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsampling, propagation, and netNMF\n",
    "After the pre-computation of the regularization graph laplacian and the network propagation kernel, we perform the core steps of the NBS algorithm multiple times (100x here) to produce multiple patient clusters that will be used in the later consensus clustering step. Each patient clustering is performed with the following steps:  \n",
    "  \n",
    "__1. Subsample binary somatic mutation data__\n",
    ">  i. Reduce binary somatic mutation data matrix to only contain columns of genes found in the network.  \n",
    ">  ii. Sub-sample rows (samples/tumors) and columns (network genes) of the binary somatic mutation matrix. Default is 80% of each axis. This can be changed with the *pats\\_subsample\\_p* and *gene\\_subsample\\_p* value in the parameter file/dictionary.  \n",
    ">  iii. Filter all rows with less than the minimum number of mutations. Default is 10 mutations. This can be changed with the *min\\_muts* value in the parameter file/dictionary.  \n",
    "  \n",
    "__2. Propagate binary somatic mutation data over network__\n",
    ">  i. If no network propagation kernel is pre-computed/provided, use the closed form of the random walk model over the full network by subgraphs (HotNet2)  \n",
    "> ii. If a pre-calculated kernel is provided, calculate individual propagation profiles by calculating the column sums of all genes mutated in the patient for each patient. This method saves a significant amount of time when performing many iterations of these steps.  \n",
    "  \n",
    "__3. Quantile normalize the network-smoothed mutation data__\n",
    ">  i. Sort each patient by gene propagation value  \n",
    ">  ii. Rank averages for each gene across samples  \n",
    ">  iii. Assign ranked averages to ranks of each gene for each sample  \n",
    "  \n",
    "__4. Use netNMF to decompose network data into k clusters__\n",
    ">  i. In each iteration, update W and H with network constraints until W and H converge  \n",
    "> ii. Track reconstruction errors and residuals  \n",
    "  \n",
    "These steps are wrapped by the `pyNBS_single()` function, which calls each step above as a different function from the `pyNBS_core module` (with the exception of the network propagation step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of pyNBS clusters\n",
    "The default number of clusters constructed by pyNBS is k=3. In this example however, there are 4 clusters. We change that definition explicitly below in the parameters for ```pyNBS_single()```. Other parameters such as the subsampling parameters and the propagation coefficient (when no kernel is pre-computed) can also be changed using \\*\\*kwargs. \\*\\*kwargs can also will hold the values of \\*\\*save_args as seen in previous functions if the user would like to save the resulting dimension reduced patient profiles. All documentation of \\*\\*kwargs definitions are given in the Github wiki page for ```pyNBS_single```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of pyNBS iterations\n",
    "The consensus clustering step of the pyNBS algorithm will improve if the data is subsampled, and re-clustered multiple times. The default number of times we perform the aforementioned operation (```niter```) is 100 times. The number can be reduced for faster run-time, but may produce less robust results. Increasing ```niter``` will increase overall runtime, but should produce more robust cluster assignments during consensus clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the number of times to perform pyNBS core steps\n",
    "niter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBS iteration: 1 complete: 113.03332901 seconds\n",
      "NBS iteration: 2 complete: 105.052984953 seconds\n",
      "NBS iteration: 3 complete: 106.535747051 seconds\n",
      "NBS iteration: 4 complete: 108.03895092 seconds\n",
      "NBS iteration: 5 complete: 101.093607903 seconds\n",
      "NBS iteration: 6 complete: 107.416523933 seconds\n",
      "NBS iteration: 7 complete: 100.349370956 seconds\n",
      "NBS iteration: 8 complete: 102.024100065 seconds\n",
      "NBS iteration: 9 complete: 104.699767828 seconds\n",
      "NBS iteration: 10 complete: 102.060678959 seconds\n",
      "NBS iteration: 11 complete: 100.067955017 seconds\n",
      "NBS iteration: 12 complete: 105.964257002 seconds\n",
      "NBS iteration: 13 complete: 103.388417959 seconds\n",
      "NBS iteration: 14 complete: 100.435489178 seconds\n",
      "NBS iteration: 15 complete: 104.857034922 seconds\n",
      "NBS iteration: 16 complete: 104.247004032 seconds\n",
      "NBS iteration: 17 complete: 103.204976082 seconds\n",
      "NBS iteration: 18 complete: 98.8112001419 seconds\n",
      "NBS iteration: 19 complete: 106.818500042 seconds\n",
      "NBS iteration: 20 complete: 105.698764801 seconds\n",
      "NBS iteration: 21 complete: 101.730262995 seconds\n",
      "NBS iteration: 22 complete: 102.956455946 seconds\n",
      "NBS iteration: 23 complete: 101.961884022 seconds\n",
      "NBS iteration: 24 complete: 102.307976007 seconds\n",
      "NBS iteration: 25 complete: 104.995671034 seconds\n",
      "NBS iteration: 26 complete: 104.16210413 seconds\n",
      "NBS iteration: 27 complete: 102.026146889 seconds\n",
      "NBS iteration: 28 complete: 103.881937027 seconds\n",
      "NBS iteration: 29 complete: 98.8194689751 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-79fcf1299ba3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnetNMF_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Run pyNBS core steps and save resulting H matrix to Hlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mHlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyNBS_single\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNBS_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpropNet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpropNet_kernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregNet_glap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknnGlap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m##########################################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cellar/users/jkhuang/anaconda/lib/python2.7/site-packages/pyNBS-0.1.0-py2.7.egg/pyNBS/pyNBS_single.pyc\u001b[0m in \u001b[0;36mNBS_single\u001b[1;34m(sm_mat, regNet_glap, propNet, propNet_kernel, prop_data, qnorm_data, k, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     W, H, numIter, finalResid = core.mixed_netNMF(data_arr, regNet_glap_arr, k=k, \n\u001b[0;32m    119\u001b[0m         \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetNMF_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetNMF_maxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetNMF_eps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         err_tol=netNMF_err_tol, err_delta_tol=netNMF_err_delta_tol, verbose=netNMF_verbose)\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m# Return netNMF result (dimension-reduced propagated patient profiles)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cellar/users/jkhuang/anaconda/lib/python2.7/site-packages/pyNBS-0.1.0-py2.7.egg/pyNBS/pyNBS_core.pyc\u001b[0m in \u001b[0;36mmixed_netNMF\u001b[1;34m(data, KNN_glap, k, gamma, maxiter, eps, err_tol, err_delta_tol, verbose)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optional: Saving the intermediate propagation step (from subsampled data) to file\n",
    "# save_args['save_prop'] = True\n",
    "\n",
    "# Run pyNBS 'niter' number of times\n",
    "Hlist = []\n",
    "for i in range(niter):\n",
    "    netNMF_time = time.time()\n",
    "    # Run pyNBS core steps and save resulting H matrix to Hlist\n",
    "    Hlist.append(pyNBS_single.NBS_single(sm_mat, propNet=network, propNet_kernel=kernel, regNet_glap=knnGlap, k=clusters))\n",
    "    \n",
    "    ##########################################################################################################\n",
    "    # Optional: If the user is saving intermediate outputs (propagation results or H matrices), \n",
    "    # a different 'iteration_label' should be used for each call of pyNBS_single().\n",
    "    # Otherwise, the user will overwrite each H matrix at each call of pyNBS_single()\n",
    "    # Uncomment and run the two lines below to save intermediate steps instead of the previous line\n",
    "    # save_args['iteration_label']=str(i+1)\n",
    "    # Hlist.append(pyNBS_single.NBS_single(sm_mat, propNet=network, propNet_kernel=kernel, regNet_glap=knnGlap, \n",
    "    #                                      k=clusters, **save_args))\n",
    "    ##########################################################################################################\n",
    "    \n",
    "    # Report run time of each pyNBS iteration\n",
    "    t = time.time()-netNMF_time\n",
    "    print 'NBS iteration:', i+1, 'complete:', t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus Clustering\n",
    "In order to produce robust patient clusters, the sub-sampling and re-clustering steps as done above are needed. After the patient data is subsampled multiple times (default=100), we perform the following step on each individual clustering result to create a single consensus clustering of all patients.  \n",
    "  \n",
    "__Steps for consensus clustering__\n",
    "1. Assign each patient to a cluster by the argmax column in the 'H' matrix for each netNMF result (termed 'hard cluster assignment')\n",
    "2. Construct patient x patient co-clustering matrix where each element is the proportion of all clustering iterations where any two patients were assigned to the same cluster.\n",
    "3. Transform this simiarity matrix into a distance matrix by taking 1-[co_clustering_matrix]\n",
    "4. Apply hierarchical clustering to the resulting distance matrix from (3) by average linkage and cut the hierarchy at desired depth k (the number of clusters, default is 3) to assign patients to a consensus cluster.\n",
    "\n",
    "This step uses the consensus_hclust_hard() function in the conensus_clustering module. It accepts a list of pandas dataframes as generated in the previous step. If the H matrices were generated separately and saved to a directory, the user will need to manually import those H matrices into a python list first before passing the list to the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NBS_cc_table, NBS_cc_linkage, NBS_cluster_assign = cc.consensus_hclust_hard(Hlist, k=clusters, **save_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Clustering Map\n",
    "To visualize the clusters formed by the pyNBS algorithm, we can plot a similarity map using the objects created in the previous step. We will also load data from the original Hofree et al 2013 paper to compare the results of the pyNBS implementation of the algorithm to the results reported in the paper. This step uses the `cluster_color_assign()` and `plot_cc_map()` functions in the `pyNBS_plotting` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First load the cluster assignment data from Hofree 2013 for ovarian cancer patients\n",
    "orig_Hofree_OV_clust = pd.read_table('./Example_Notebook_Data/Hofree_Results/Hofree_OV_NBS_Results.csv',sep=',',index_col=0)\n",
    "\n",
    "# Align the pyNBS and Hofree cluster assignments with one another using Pandas\n",
    "cluster_align = pd.concat([orig_Hofree_OV_clust.iloc[:,0], NBS_cluster_assign], axis=1).dropna(axis=0, how='any').astype(int)\n",
    "Hofree_OV_clust = cluster_align.iloc[:,0].astype(int)\n",
    "pyNBS_OV_clust = cluster_align.iloc[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign colors to clusters from Hofree and pyNBS\n",
    "Hofree_OV_clust_cmap = plot.cluster_color_assign(Hofree_OV_clust, name='Hofree OV Cluster Assignments')\n",
    "pyNBS_OV_clust_cmap = plot.cluster_color_assign(pyNBS_OV_clust, name='pyNBS OV Cluster Assignments')\n",
    "\n",
    "# Plot and save co-cluster map figure\n",
    "plot.plot_cc_map(NBS_cc_table, NBS_cc_linkage, row_color_map=Hofree_OV_clust_cmap, col_color_map=pyNBS_OV_clust_cmap, **save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename = pyNBS_params['outdir']+pyNBS_params['job_name']+'_cc_map.png', width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival analysis\n",
    "To determine if the patient clusters are prognostically relevant, we perform a standard survival analysis using a multi-class logrank test to evaluate the significance of survival separation between patient clusters. This data is plotted using a Kaplan-Meier plot using the `cluster_KMplot()` in the `pyNBS_plotting` module. However in order to plot the survival differences between clusters, we will need to load survival data for each patient. This data was extracted from TCGA clinical data. The survival data is given in a 4-column delimited table with the specific headings described below (the columns must be in the same order as shown below). \n",
    "  \n",
    "__Survival Table Column Headers:__\n",
    " - `vital_status`: Binary (0/1) value of whether or not the patient is alive (censored). 0 for alive, 1 for dead.\n",
    " - `days_to_death`: If the patient has a death event in the `vital_status` column, this is the number of days the patient survived from diagonsis. Otherwise the value is 0 if the patient is still alive.\n",
    " - `days_to_last_followup`: If the patient is still alive, this the last time the patient was known to have followed up and was still alive. Otherwise the value is 0 if the patient is dead.\n",
    " - `overall_survival`: This is either the days until the patient's death or until their last follow-up. This is the max of the aforementioned previous 2 columns.\n",
    "\n",
    "The following is an example of a few lines of the Hofree OV survival table:  \n",
    "\n",
    "||vital_status|days_to_death|days_to_last_followup|overall_survival|\n",
    "|-|-|-|-|-|\n",
    "|TCGA-3P-A9WA|0|0|420|420|\n",
    "|TCGA-59-A5PD|1|624|0|624|\n",
    "|TCGA-5X-AA5U|0|0|361|361|\n",
    "|TCGA-04-1331|1|1336|0|1336|\n",
    "|TCGA-04-1332|1|1247|0|1247|\n",
    "\n",
    "Note: The default setting for pyNBS is that no survival curves are drawn because the survival data is not a required parameter. The path to valid survival data must be explicitly defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load survival Data\n",
    "surv_data = './Example_Notebook_Data/Clinical_Files/OV.clin.merged.Hofree.txt'\n",
    "\n",
    "# Plot KM Plot for patient clusters\n",
    "plot.cluster_KMplot(NBS_cluster_assign, surv_data, delimiter=',', **save_args)\n",
    "Image(filename = pyNBS_params['outdir']+pyNBS_params['job_name']+'_KM_plot.png', width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyNBS Result comparison to Hofree et al 2013\n",
    "We also compare the pyNBS clustering results against the original Hofree 2013 cluster assignments of the same patient data using two scores: adjusted rand index and adjusted mutual information score.\n",
    "  \n",
    "__Adjusted Rand Index (ARI)__\n",
    "> Rand index adjusted for chance.\n",
    "$$ARI = \\frac{RI - \\mathbb{E}(RI)}{ \\max(RI) - \\mathbb{E}(RI)}$$\n",
    "\n",
    "__Adjusted Mutual Info Score (AMI)__\n",
    "> Adjusted Mutual Information between two clusterings.\n",
    "$${AMI(U, V) = \\frac{MI(U, V) - \\mathbb{E}(MI(U, V))}{\\max(H(U), H(V)) - \\mathbb{E}(MI(U, V))}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_mutual_info_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_rand_index = adjusted_rand_score(Hofree_OV_clust, pyNBS_OV_clust)\n",
    "adj_mutual_info_score = adjusted_mutual_info_score(Hofree_OV_clust, pyNBS_OV_clust)\n",
    "print 'Adjusted Rand Index is: ' + str(adj_rand_index)\n",
    "print 'Adjusted Mutual Info Score is: ' + str(adj_mutual_info_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
